<!DOCTYPE html>
<html lang="ja">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>これは何棟？</title>
    <link rel="stylesheet" href="style.css">
  </head>
  <body>
    <section id="startScreen">
      <h1>これは何棟？</h1>
      <button id="startButton" type="button" onclick="init()">スタート</button>
    </section>

    <section id="mainScreen" style="display: none;">
      <span class="please-point-camera">校舎にカメラを向けてください</span>
      <div id="webcam-container"></div>
      <div id="label-container"></div>
      <div class="result">
        <span class="this-building-is">この棟は...</span>
        <span class="result-text" id="resultText">認識中</span>
      </div>
    </section>

    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@latest/dist/teachablemachine-image.min.js"></script>
    <script type="text/javascript">
      // More API functions here:
      // https://github.com/googlecreativelab/teachablemachine-community/tree/master/libraries/image

      // the link to your model provided by Teachable Machine export panel
      const URL = "./model/";

      let model, webcam, labelContainer, maxPredictions;

      const buildingNames = {
        "kentiku": "建築棟",
        "tosyo": "図書センター",
        "kougi": "講義棟",
        "denbutu": "電物棟",
        "denden": "電電棟",
        "monosen": "モノづくりセンター",
        "kanri": "管理棟",
        "tekuno": "テクノ棟",
        "dai1taiikukan": "第1体育館",
        "dai2taiikukan": "第2体育館",
        "kikai": "機械棟"
      };
      const resultTextElem = document.getElementById("resultText");
      // 外カメラ設定
      const videoConstraints = {
        video: {
          facingMode: { ideal: "environment" },
          width: { ideal: 800 },
          height: { ideal: 800 }
        }
      };

      // Load the image model and setup the webcam
      async function init() {
        document.getElementById("startButton").textContent = "読み込み中...";
        document.getElementById("startButton").disabled = true;

        const modelURL = URL + "model.json";
        const metadataURL = URL + "metadata.json";

        // load the model and metadata
        // Refer to tmImage.loadFromFiles() in the API to support files from a file picker
        // or files from your local hard drive
        // Note: the pose library adds "tmImage" object to your window (window.tmImage)
        model = await tmImage.load(modelURL, metadataURL);
        maxPredictions = model.getTotalClasses();

        const stream = await navigator.mediaDevices.getUserMedia(videoConstraints);
        const video = document.createElement('video');
        video.srcObject = stream;
        video.play();

        document.getElementById("webcam-container").appendChild(video);

        // Convenience function to setup a webcam
        const flip = false; // whether to flip the webcam
        webcam = new tmImage.Webcam(800, 800, flip); // width, height, flip
        await webcam.setup(); // request access to the webcam
        webcam.webcam = video;
        window.requestAnimationFrame(loop);

        // append elements to the DOM
        // document.getElementById("webcam-container").appendChild(webcam.canvas);
        labelContainer = document.getElementById("label-container");
        for (let i = 0; i < maxPredictions; i++) { // and class labels
          labelContainer.appendChild(document.createElement("div"));
        }

        // 画面切り替え
        document.getElementById("startScreen").style.display = "none";
        document.getElementById("mainScreen").style.display = "flex";
      }

      async function loop() {
        // webcam.update(); // update the webcam frame
        await predict();
        window.requestAnimationFrame(loop);
      }

      // run the webcam image through the image model
      async function predict() {
        // predict can take in an image, video or canvas html element
        const prediction = await model.predict(webcam.canvas);
        const result = [];
        for (let i = 0; i < maxPredictions; i++) {
          const classPrediction = prediction[i].className + ": " + prediction[i].probability.toFixed(2);
          labelContainer.childNodes[i].innerHTML = classPrediction;
          // 結果を配列に追加
          result.push({[prediction[i].className]: prediction[i].probability.toFixed(2)});
        }
        
        // 一番高いものを見つける
        const max = result.reduce((max, current) => {
            const key = Object.keys(current)[0];
            const value = parseFloat(current[key]);

            return value > max.value ? { key, value } : max;
        }, { key: null, value: -Infinity });
        // 画面に反映
        if (max.value <= 0.5) {
          resultTextElem.textContent = "認識中...";
        } else {
          resultTextElem.textContent = buildingNames[max.key] + ` (${Math.floor(max.value * 100)}%)`;
        }
      }
    </script>
  </body>
</html>